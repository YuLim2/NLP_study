{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 불용어\n",
    "큰 의미가 없는 단어 토큰을 제거하는 작업이 필요<br>\n",
    "큰 의미가 없다는 것은 분석을 할 때 큰 도움이 되지 않는 단어들<br> \n",
    "ex)<br>\n",
    "I, my, me, over, 조사, 접미사 ...\n",
    "\n",
    "NLTK에서는 불용어들을을 **패키지로 정의**하고 있다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 :  179\n",
      "불용어 10개 :  ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    }
   ],
   "source": [
    "# NLTK의 불용어 확인\n",
    "stop_words_list = stopwords.words('english')\n",
    "print('불용어 개수 : ', len(stop_words_list))\n",
    "print('불용어 10개 : ', stop_words_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 제거 전 :  ['I', 'can', 'drive', 'my', 'car', '.', 'We', \"'re\", 'happy', 'person']\n",
      "불용어 제거 후 :  ['I', 'drive', 'car', '.', 'We', \"'re\", 'happy', 'person']\n"
     ]
    }
   ],
   "source": [
    "# NLTK를 통해 불용어 제거\n",
    "text = \"I can drive my car. We're happy person\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(text)\n",
    "\n",
    "result=[]\n",
    "for word in word_tokens:\n",
    "    if word not in stop_words:\n",
    "        result.append(word)\n",
    "        \n",
    "print('불용어 제거 전 : ', word_tokens)\n",
    "print('불용어 제거 후 : ', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한국어에서 불용어 제거\n",
    "제거하는 방법\n",
    "- 토큰화 후에 조사, 접속사 등을 제거\n",
    "- 직접 불용어 정의 후 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 제거 전 :  ['지금', '석식', '시간', '이', '얼마', '안', '남았다', '.', '빨리', '마치', '고', '석식', '먹고', '공부', '하고', '기숙사', '가고', '싶다', '.', '그나마', '내일', '은', '집', '을', '가서', '너무', '다행', '이다', '.']\n",
      "불용어 제거 후 :  ['지금', '석식', '시간', '안', '남았다', '.', '빨리', '석식', '먹고', '하고', '기숙사', '가고', '싶다', '.', '그나마', '내일', '집', '을', '가서', '너무', '다행', '이다', '.']\n"
     ]
    }
   ],
   "source": [
    "# 한국어에서 불용어 제거\n",
    "okt = Okt()\n",
    "\n",
    "text2 = \"지금 석식 시간이 얼마 안 남았다. 빨리 마치고 석식 먹고 공부하고 기숙사 가고 싶다. 그나마 내일은 집을 가서 너무 다행이다.\"\n",
    "stop_words2 = \"이  고 은 가 서 얼마 마치 고 공부 하 고\"\n",
    "\n",
    "stop_words2 = set(stop_words2.split(' '))\n",
    "word_tokens2=okt.morphs(text2)\n",
    "\n",
    "result2 = [word for word in word_tokens2 if not word in stop_words2]\n",
    "print('불용어 제거 전 : ', word_tokens2)\n",
    "print('불용어 제거 후 : ', result2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env] *",
   "language": "python",
   "name": "conda-env-data_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
